# Data Pipeline Project

## Description

This projects scraps Pingo Doce, Continente and Auchan (so far), uploads to s3 and creates a structured SQL database. 
This workflow is scheduled an hosted with github actions.

## Objectives

- Scrap data from html/http sources 
- Save this data in S3 buckets raw
- Create a pipeline which loads data from S3 buckets
- Create a transform pipeline which preprocesses and structures the data
- Create great-expectations data quality audits before inserting the data in SQL
- Create a data interface class which inserts data in SQL according to data schema
- Good practices of continuous integration
- Employ pipeline design patterns which ease debugging

## SQL database schema

[
  {
    "table_schema": "public",
    "table_name": "category_hierarchy",
    "column_name": "category_id",
    "is_pk": "PRIMARY KEY",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "category_hierarchy",
    "column_name": "category_level1",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "category_hierarchy",
    "column_name": "category_level2",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "category_hierarchy",
    "column_name": "category_level3",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product",
    "column_name": "product_id_pk",
    "is_pk": "PRIMARY KEY",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product",
    "column_name": "product_id",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product",
    "column_name": "product_name",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product",
    "column_name": "source",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product_category",
    "column_name": "product_id_pk",
    "is_pk": "PRIMARY KEY",
    "is_fk": "FOREIGN KEY"
  },
  {
    "table_schema": "public",
    "table_name": "product_category",
    "column_name": "category_id",
    "is_pk": "PRIMARY KEY",
    "is_fk": "FOREIGN KEY"
  },
  {
    "table_schema": "public",
    "table_name": "product_pricing",
    "column_name": "product_id_pk",
    "is_pk": " ",
    "is_fk": "FOREIGN KEY"
  },
  {
    "table_schema": "public",
    "table_name": "product_pricing",
    "column_name": "price_integer",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product_pricing",
    "column_name": "price_decimal",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product_pricing",
    "column_name": "price_currency",
    "is_pk": " ",
    "is_fk": " "
  },
  {
    "table_schema": "public",
    "table_name": "product_pricing",
    "column_name": "timestamp",
    "is_pk": " ",
    "is_fk": " "
  }
]

## Project Structure
- ğŸ“ continente_price_tracker/
  - ğŸ“ notebooks/
  - ğŸ“ src/
    - ğŸ“ db/
      - ğŸ“ ingestion/
        - ğŸ“ __pycache__/
        - ğŸ“„ __init__.py
        - ğŸ“„ ge.py
        - ğŸ“„ preprocessing.py
        - ğŸ“„ transformer.py
        - ğŸ“„ utils.py
    - ğŸ“ models/
      - ğŸ“ __pycache__/
      - ğŸ“„ __init__.py
      - ğŸ“„ ingestion.py
      - ğŸ“„ main.py
      - ğŸ“ object_storage/
        - ğŸ“ scraper/
          - ğŸ“„ __init__.py
          - ğŸ“„ auchan.py
          - ğŸ“„ catalogo.py
          - ğŸ“„ pingo_doce.py
        - ğŸ“„ __init__.py
        - ğŸ“„ main.py
    - ğŸ“„ __init__.py
    - ğŸ“„ logger.py
    - ğŸ“„ main_concurrency.py
    - ğŸ“„ utils.py


